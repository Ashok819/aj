<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>One-Line AI Explainer</title>

  <!-- TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0"></script>

  <!-- COCO-SSD -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

  <style>
    body {
      font-family: Arial, sans-serif;
      background: #0f172a;
      color: white;
      display: flex;
      flex-direction: column;
      align-items: center;
      padding: 20px;
    }

    video {
      width: 90%;
      max-width: 400px;
      border-radius: 12px;
      margin-bottom: 15px;
    }

    .card {
      background: #1e293b;
      padding: 15px;
      border-radius: 12px;
      width: 90%;
      max-width: 400px;
      text-align: center;
      font-size: 18px;
      margin-bottom: 10px;
    }

    button {
      width: 90%;
      max-width: 400px;
      padding: 12px;
      border-radius: 10px;
      border: none;
      font-size: 16px;
      background: #3b82f6;
      color: white;
      cursor: pointer;
    }

    button:active {
      transform: scale(0.98);
    }

    .status {
      margin-top: 10px;
      font-size: 14px;
      opacity: 0.7;
    }
  </style>
</head>
<body>

  <h2>üëÅÔ∏è One-Line AI Explainer</h2>

  <video id="video" autoplay muted playsinline></video>

  <div class="card" id="output">
    Press ‚ÄúExplain‚Äù to analyze scene
  </div>

  <button id="explainBtn">Explain Scene</button>

  <div class="status" id="status"></div>

  <script>
    const video = document.getElementById("video");
    const output = document.getElementById("output");
    const statusText = document.getElementById("status");
    const explainBtn = document.getElementById("explainBtn");

    let model;
    let latestObjects = [];

    async function startCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "environment" },
        audio: false
      });
      video.srcObject = stream;
    }

    function createSentence(objects) {
      if (objects.length === 0) return "I don‚Äôt see anything clearly.";

      const unique = [...new Set(objects)];
      if (unique.length === 1) {
        return `I see a ${unique[0]}.`;
      }
      if (unique.length === 2) {
        return `I see a ${unique[0]} and a ${unique[1]}.`;
      }
      return `I see ${unique.slice(0, 3).join(", ")}.`;
    }

    async function detectLoop() {
      const predictions = await model.detect(video);

      latestObjects = predictions
        .filter(p => p.score > 0.6)
        .map(p => p.class);

      requestAnimationFrame(detectLoop);
    }

    explainBtn.onclick = () => {
      const sentence = createSentence(latestObjects);
      output.innerText = sentence;
    };

    async function init() {
      statusText.innerText = "Starting camera‚Ä¶";
      await startCamera();

      statusText.innerText = "Loading AI model‚Ä¶";
      model = await cocoSsd.load();

      statusText.innerText = "Ready. Tap Explain üëá";
      detectLoop();
    }

    init();
  </script>

</body>
</html>
